{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJRIeRBap_sO"
      },
      "source": [
        "Run the cell below to finetune the pretrained model to suit your dataset.\n",
        "<br>\n",
        "<br>\n",
        "Once done, download best_model.pth and classifications.txt, this is the model that has been finetuned on your data and the cell names that model has learnt.\n",
        "<br>\n",
        "<br>\n",
        "Proceed to bottom to use cell identifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "aFX6mScSnprv"
      },
      "outputs": [],
      "source": [
        "import shutil, torch, timm, os\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def create_folder(foldername):\n",
        "  try:\n",
        "    os.mkdir(foldername)\n",
        "\n",
        "  except FileExistsError:\n",
        "    print(f\"{foldername} already exists.\")\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "def split_new_data():\n",
        "  source_directory = \"/content/drive/MyDrive/MNT/Dataset\"\n",
        "\n",
        "  try:\n",
        "    folders = os.listdir(source_directory) # access new data if there is any\n",
        "\n",
        "    for folder in folders: # access each new cell type added\n",
        "      folder_path = os.path.join(source_directory, folder)\n",
        "      files = os.listdir(folder_path)\n",
        "\n",
        "      validate_path = os.path.join(\"/content/drive/MyDrive/MNT/Training Dataset/Validate\", folder)\n",
        "      training_path = os.path.join(\"/content/drive/MyDrive/MNT/Training Dataset/Train\", folder)\n",
        "\n",
        "      create_folder(validate_path)\n",
        "      create_folder(training_path)\n",
        "\n",
        "      size = len(files)\n",
        "      train = (size * 8) // 10 # 80% of cell images will be used for training, remaining for validation\n",
        "\n",
        "      for f in files[:train]:\n",
        "        current_path = os.path.join(folder_path, f)\n",
        "        new_path = os.path.join(training_path, f)\n",
        "        shutil.move(current_path, new_path)\n",
        "\n",
        "      for f in files[train:]:\n",
        "        current_path = os.path.join(folder_path, f)\n",
        "        new_path = os.path.join(validate_path, f)\n",
        "        shutil.move(current_path, new_path)\n",
        "\n",
        "  except FileNotFoundError:\n",
        "    print(\"No new data found.\")\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "def train_epoch(loader, model, criterion, optimizer, device):\n",
        "  model.train()\n",
        "  total_loss, total_correct = 0.0, 0\n",
        "\n",
        "  for imgs, labels in loader:\n",
        "      imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(imgs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      total_loss += loss.item() * imgs.size(0)\n",
        "      total_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "  avg_loss = total_loss / len(loader.dataset)\n",
        "  avg_acc = total_correct / len(loader.dataset)\n",
        "\n",
        "  return avg_loss, avg_acc\n",
        "\n",
        "\n",
        "def eval_epoch(loader, model, criterion, device):\n",
        "  model.eval()\n",
        "  total_loss, total_correct = 0.0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for imgs, labels in loader:\n",
        "          imgs, labels = imgs.to(device), labels.to(device)\n",
        "          outputs = model(imgs)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          total_loss += loss.item() * imgs.size(0)\n",
        "          total_correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "  avg_loss = total_loss / len(loader.dataset)\n",
        "  avg_acc = total_correct / len(loader.dataset)\n",
        "  return avg_loss, avg_acc\n",
        "\n",
        "\n",
        "def finetune(num_epochs):\n",
        "  # Imagenet normalisation statistics\n",
        "  mean = [0.485, 0.456, 0.406]\n",
        "  std = [0.229, 0.224, 0.225]\n",
        "\n",
        "  # makes dataset larger\n",
        "  train_transform = transforms.Compose([\n",
        "      transforms.RandomResizedCrop(224),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean, std),\n",
        "  ])\n",
        "\n",
        "  # crop images to 224x224px for deep learning\n",
        "  val_transform = transforms.Compose([\n",
        "      transforms.Resize(256),\n",
        "      transforms.CenterCrop(224),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean, std),\n",
        "  ])\n",
        "\n",
        "  # access training dataset\n",
        "  train_ds = datasets.ImageFolder(\"/content/drive/MyDrive/MNT/Training Dataset/Train\", transform=train_transform)\n",
        "  val_ds = datasets.ImageFolder(\"/content/drive/MyDrive/MNT/Training Dataset/Validate\", transform=val_transform)\n",
        "\n",
        "  train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=4)\n",
        "  val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "  num_classes = len(train_ds.classes)\n",
        "\n",
        "  # load in EfficientNet-LiteB0 pretrained model\n",
        "  model = timm.create_model('efficientnet_lite0', pretrained=True)\n",
        "\n",
        "  # replace classifications\n",
        "  in_features = model.classifier.in_features\n",
        "  model.classifier = nn.Linear(in_features, num_classes)\n",
        "\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  model = model.to(device)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "  best_val_acc = 0.0\n",
        "  patience = 10\n",
        "  no_improvement_epochs = 0\n",
        "\n",
        "  for epoch in tqdm(range(num_epochs), desc=\"Training\"):\n",
        "      train_loss, train_acc = train_epoch(train_loader, model, criterion, optimizer, device)\n",
        "\n",
        "      val_loss, val_acc = eval_epoch(val_loader, model, criterion, device)\n",
        "\n",
        "      scheduler.step()\n",
        "\n",
        "      if val_acc > best_val_acc:\n",
        "          best_val_acc = val_acc\n",
        "          no_improvement_epochs = 0\n",
        "          torch.save(model.state_dict(), 'best_model.pth') # save best model\n",
        "      else:\n",
        "          no_improvement_epochs += 1\n",
        "\n",
        "      if no_improvement_epochs >= patience: # early exit to prevent overfitting\n",
        "          print(f\"Early stopping at epoch {epoch+1}. No improvement in the last {patience} epochs.\")\n",
        "          break\n",
        "\n",
        "  with open(\"classifications.txt\", \"w\") as file: # write classifications file\n",
        "    file.write(train_ds.classes[0])\n",
        "    for Class in train_ds.classes[1:]:\n",
        "        file.write(f\"\\n{Class}\")\n",
        "\n",
        "  print(\"Finished finetuning.\")\n",
        "\n",
        "  return\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "  split_new_data() # place new data in dataset in training and validation if there is any\n",
        "\n",
        "  finetune(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31fym-PRMI00"
      },
      "source": [
        "Cell Identifier.\n",
        "<br>\n",
        "<br>\n",
        "Ensure classifications.txt and best_model.pth has been uploaded to files under content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWTEjS1P_AYl",
        "outputId": "8a4ec5dd-bdbb-4ced-df94-b0ba77d6620a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cellpose\n",
            "  Downloading cellpose-4.0.6-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from cellpose) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from cellpose) (1.16.0)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.11/dist-packages (from cellpose) (8.4.0)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.11/dist-packages (from cellpose) (2025.6.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from cellpose) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.11/dist-packages (from cellpose) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from cellpose) (0.21.0+cu124)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from cellpose) (4.12.0.88)\n",
            "Collecting fastremap (from cellpose)\n",
            "  Downloading fastremap-1.17.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting imagecodecs (from cellpose)\n",
            "  Downloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting roifile (from cellpose)\n",
            "  Downloading roifile-2025.5.10-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting fill-voids (from cellpose)\n",
            "  Downloading fill_voids-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Collecting segment_anything (from cellpose)\n",
            "  Downloading segment_anything-1.0-py3-none-any.whl.metadata (487 bytes)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->cellpose) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->cellpose) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->cellpose) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->cellpose) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->cellpose) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.6->cellpose)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.6->cellpose)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.6->cellpose)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.6->cellpose)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.6->cellpose)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.6->cellpose)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.6->cellpose)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.6->cellpose)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.6->cellpose)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->cellpose) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->cellpose) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->cellpose) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.6->cellpose)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->cellpose) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6->cellpose) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6->cellpose) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->cellpose) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6->cellpose) (3.0.2)\n",
            "Downloading cellpose-4.0.6-py3-none-any.whl (212 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.3/212.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastremap-1.17.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fill_voids-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading roifile-2025.5.10-py3-none-any.whl (17 kB)\n",
            "Downloading segment_anything-1.0-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: segment_anything, roifile, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, imagecodecs, fastremap, nvidia-cusparse-cu12, nvidia-cudnn-cu12, fill-voids, nvidia-cusolver-cu12, cellpose\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed cellpose-4.0.6 fastremap-1.17.2 fill-voids-2.1.0 imagecodecs-2025.3.30 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 roifile-2025.5.10 segment_anything-1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install cellpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHPbpRfgJ3GT",
        "outputId": "2a073374-c67d-4069-89f7-da143b8df8aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted classification of [[[216 255 255]\n",
            "  [218 255 255]\n",
            "  [209 251 250]\n",
            "  ...\n",
            "  [189 203 212]\n",
            "  [195 208 216]\n",
            "  [195 208 216]]\n",
            "\n",
            " [[220 255 255]\n",
            "  [221 255 255]\n",
            "  [208 252 251]\n",
            "  ...\n",
            "  [185 199 208]\n",
            "  [195 208 217]\n",
            "  [195 208 216]]\n",
            "\n",
            " [[213 255 254]\n",
            "  [212 254 253]\n",
            "  [197 241 240]\n",
            "  ...\n",
            "  [171 185 194]\n",
            "  [179 192 201]\n",
            "  [179 192 201]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[176 185 200]\n",
            "  [190 202 216]\n",
            "  [169 185 198]\n",
            "  ...\n",
            "  [  3   8   2]\n",
            "  [  0   1   0]\n",
            "  [ 12  14  13]]\n",
            "\n",
            " [[155 159 171]\n",
            "  [190 196 208]\n",
            "  [181 191 203]\n",
            "  ...\n",
            "  [  0   2   0]\n",
            "  [ 11  11  11]\n",
            "  [ 56  56  58]]\n",
            "\n",
            " [[148 152 164]\n",
            "  [201 207 219]\n",
            "  [194 204 216]\n",
            "  ...\n",
            "  [  2   7   3]\n",
            "  [  1   1   1]\n",
            "  [ 60  60  62]]]: Animal_Cell_Mitosis_Cell  (confidence: 80.26%) (cell count: 373)\n"
          ]
        }
      ],
      "source": [
        "import torch, timm, cv2\n",
        "import cellpose\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from cellpose import models\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  with open(\"classifications.txt\", \"r\") as file:\n",
        "      classes = [line.strip() for line in file]\n",
        "  num_classes = len(classes)\n",
        "\n",
        "  cellpose_model = models.CellposeModel(gpu=\"True\")\n",
        "  identifier_model = timm.create_model('efficientnet_lite0', pretrained=False)\n",
        "\n",
        "  in_features = identifier_model.classifier.in_features\n",
        "  identifier_model.classifier = torch.nn.Linear(in_features, num_classes)\n",
        "\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "  finetuned_model = torch.load('best_model.pth', map_location=device)\n",
        "  identifier_model.load_state_dict(finetuned_model)\n",
        "  identifier_model = identifier_model.to(device)\n",
        "  identifier_model.eval()\n",
        "\n",
        "  mean = [0.485, 0.456, 0.406]\n",
        "  std  = [0.229, 0.224, 0.225]\n",
        "\n",
        "  val_transform = transforms.Compose([\n",
        "      transforms.Resize(256),\n",
        "      transforms.CenterCrop(224),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean, std),\n",
        "  ])\n",
        "\n",
        "  while True:\n",
        "    image = Image.open(input(\"Enter image path here: \")).convert(\"RGB\") # pytorch reads PIL images\n",
        "    try:\n",
        "      input_tensor = val_transform(image).unsqueeze(0).to(device)\n",
        "      break\n",
        "\n",
        "    except FileNotFoundError:\n",
        "      print(\"Image not found.\")\n",
        "\n",
        "  with torch.no_grad():\n",
        "      logits = identifier_model(input_tensor)\n",
        "      probs = torch.softmax(logits, dim=1)\n",
        "      pred_class = logits.argmax(dim=1).item()\n",
        "      pred_conf = probs[0, pred_class].item()\n",
        "\n",
        "  image = np.array(image)\n",
        "  masks, flows, styles = cellpose_model.eval(image) # cellpose reads numpy arrays\n",
        "  cell_count = len(np.unique(masks)) - 1\n",
        "\n",
        "  print(f\"Predicted classification: {classes[pred_class]}  (confidence: {pred_conf:.2%}) (cell count: {cell_count})\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}